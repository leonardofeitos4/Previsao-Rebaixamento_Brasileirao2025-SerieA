{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Jinja2 in c:\\users\\lucia\\anaconda3\\envs\\novo_ambiente_python310\\lib\\site-packages (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lucia\\anaconda3\\envs\\novo_ambiente_python310\\lib\\site-packages (from Jinja2) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Jinja2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raspagem de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos da serie A (2014 - 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coletando dados da temporada 2025...\n",
      "Temporada 2025 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2024...\n",
      "Temporada 2024 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2023...\n",
      "Temporada 2023 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2022...\n",
      "Temporada 2022 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2021...\n",
      "Temporada 2021 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2020...\n",
      "Temporada 2020 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2019...\n",
      "Temporada 2019 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2018...\n",
      "Temporada 2018 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2017...\n",
      "Temporada 2017 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2016...\n",
      "Temporada 2016 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2015...\n",
      "Temporada 2015 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2014...\n",
      "Temporada 2014 finalizada com 20 clubes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Temporadas e URLs correspondentes\n",
    "temporadas_urls = {\n",
    "    \"2025\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2024\",\n",
    "    \"2024\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2023\",\n",
    "    \"2023\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2022\",\n",
    "    \"2022\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2021\",\n",
    "    \"2021\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2020\",\n",
    "    \"2020\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2019\",\n",
    "    \"2019\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2018\",\n",
    "    \"2018\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2017\",\n",
    "    \"2017\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2016\",\n",
    "    \"2016\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2015\",\n",
    "    \"2015\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2014\",\n",
    "    \"2014\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2013\"\n",
    "}\n",
    "\n",
    "# Setup navegador headless\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Caminho para a pasta 'dados'\n",
    "dados_pasta = \"dados/Todos_serieA\"\n",
    "os.makedirs(dados_pasta, exist_ok=True)\n",
    "\n",
    "for temporada, url in temporadas_urls.items():\n",
    "    print(f\"Coletando dados da temporada {temporada}...\")\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    table = soup.find(\"table\", class_=\"items\")\n",
    "\n",
    "    clubes_data = []\n",
    "    if table:\n",
    "        rows = table.find_all(\"tr\", class_=[\"odd\", \"even\"])\n",
    "        for row in rows:\n",
    "            cols = row.find_all(\"td\")\n",
    "            if len(cols) >= 7:\n",
    "                clube = cols[1].text.strip()\n",
    "                plantel = cols[2].text.strip()\n",
    "                idade_media = cols[3].text.strip()\n",
    "                estrangeiros = cols[4].text.strip()\n",
    "                valor_medio = cols[5].text.strip()\n",
    "                valor_total = cols[6].text.strip()\n",
    "\n",
    "                clubes_data.append({\n",
    "                    \"Clube\": clube,\n",
    "                    \"Plantel\": plantel,\n",
    "                    \"√∏ Idade\": idade_media,\n",
    "                    \"Estrangeiros\": estrangeiros,\n",
    "                    \"√∏ Valor de Mercado\": valor_medio,\n",
    "                    \"Valor de Mercado Total\": valor_total\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(clubes_data)\n",
    "    df.to_csv(os.path.join(dados_pasta, f\"valores_{temporada}.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"Temporada {temporada} finalizada com {len(df)} clubes.\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos juntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Arquivo 'todos_clubes_serieA.csv' criado com sucesso e coluna 'Temporada' limpa!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pasta = os.path.join(\"dados\", \"Todos_serieA\")\n",
    "\n",
    "\n",
    "if not os.path.exists(pasta):\n",
    "    print(f\"A pasta '{pasta}' n√£o foi encontrada.\")\n",
    "else:\n",
    "    arquivos = sorted([arq for arq in os.listdir(pasta) if arq.endswith(\".csv\")])\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for arquivo in arquivos:\n",
    "        temporada = arquivo.split(\"_\")[1].split(\".\")[0] \n",
    "        df = pd.read_csv(os.path.join(pasta, arquivo))\n",
    "        df[\"Temporada\"] = temporada.strip()\n",
    "        dfs.append(df)\n",
    "\n",
    "    df_final = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    df_final[\"Temporada\"] = df_final[\"Temporada\"].str.extract(r\"(\\d{4})\")\n",
    "\n",
    "  \n",
    "    caminho_saida = os.path.join(\"dados\", \"todos_clubes_serieA.csv\")\n",
    "    \n",
    "    df_final.to_csv(caminho_saida, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(\"‚úÖ Arquivo 'todos_clubes_serieA.csv' criado com sucesso e coluna 'Temporada' limpa!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformando o arquivo BASE_FINAL xlsx em CSV \n",
    "* (O arquvio cont√©m os dados dos valores do clube + pontos por temporada que foi feito no pr√≥prio excel com a formula procv) \n",
    "* Estando na aba 'Crud' la foi feito a organiza√ß√£o dos dados para colocar na aba principal \"todos_clubes_serieA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    \n",
    "    caminho_excel = os.path.join(\"dados\", \"BASE_FINAL.xlsx\")\n",
    "\n",
    "    df = pd.read_excel(caminho_excel, sheet_name=\"CLUBES\")\n",
    "\n",
    "\n",
    "    caminho_csv = os.path.join(\"dados\", \"todos_clubes_serieA_com_pontos.csv\")\n",
    "\n",
    "    \n",
    "    df.to_csv(caminho_csv, index=False)\n",
    "\n",
    "    print(\"CSV salvo com sucesso!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Clube  Plantel  √∏ Idade  Estrangeiros  √∏ Valor de Mercado  \\\n",
      "0         S√£o Paulo       45       25             6                3.33   \n",
      "1       Corinthians       44       24             5                1.99   \n",
      "2            Santos       49       23             6                1.50   \n",
      "3  Atl√©tico Mineiro       55       25             2                1.16   \n",
      "4        Fluminense       43       23             2                1.13   \n",
      "\n",
      "   Valor de Mercado Total  Temporada  Pontos Situacao  Status  Status_bin  \n",
      "0                  149.65       2014      70     Top4     1.0           1  \n",
      "1                   87.55       2014      69     Top4     1.0           1  \n",
      "2                   73.40       2014      53     Top4     1.0           1  \n",
      "3                   63.85       2014      62     Top4     1.0           1  \n",
      "4                   48.80       2014      61   SerieA     2.0           1  \n",
      "             Clube  Plantel  √∏ Idade  Estrangeiros  √∏ Valor de Mercado  \\\n",
      "220      Palmeiras       31       26             8                7.70   \n",
      "221       Flamengo       31       27             7                7.07   \n",
      "222       Botafogo       34       26             6                4.00   \n",
      "223    Corinthians       34       26            10                3.63   \n",
      "224  Internacional       42       25             9                2.54   \n",
      "\n",
      "     Valor de Mercado Total  Temporada  Pontos Situacao  Status  Status_bin  \n",
      "220                  238.75       2025       0      NaN     NaN           1  \n",
      "221                  219.15       2025       0      NaN     NaN           1  \n",
      "222                  135.95       2025       0      NaN     NaN           1  \n",
      "223                  123.25       2025       0      NaN     NaN           1  \n",
      "224                  106.65       2025       0      NaN     NaN           1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(\"dados\", \"BASE_FINAL.xlsx\")\n",
    "\n",
    "df = pd.read_excel(file_path, sheet_name=\"CLUBES\")\n",
    "\n",
    "df['Status_bin'] = df['Status'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "df_treino = df[df['Temporada'] < 2025].copy()\n",
    "df_prev = df[df['Temporada'] == 2025].copy()\n",
    "\n",
    "print(df_treino.head())\n",
    "print(df_prev.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "features = ['Plantel', '√∏ Idade', 'Estrangeiros', '√∏ Valor de Mercado', 'Valor de Mercado Total']\n",
    "\n",
    "combinacoes = []\n",
    "for i in range(1, len(features) + 1):\n",
    "    combinacoes += list(combinations(features, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Top 3 Modelos por Acur√°cia M√©dia:\n",
      "\n",
      "   Modelo                                           Features  Acur√°cia M√©dia  \\\n",
      "84  Logit  Plantel, Estrangeiros, √∏ Valor de Mercado, Val...        0.895909   \n",
      "60  Logit  Plantel, √∏ Valor de Mercado, Valor de Mercado ...        0.895000   \n",
      "54  Logit          Plantel, Estrangeiros, √∏ Valor de Mercado        0.892727   \n",
      "\n",
      "    MAE M√©dio  RMSE M√©dio  \n",
      "84   0.104091    0.315998  \n",
      "60   0.105000    0.315020  \n",
      "54   0.107273    0.320235  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "models = {\n",
    "    'Logit': LogisticRegression(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "resultados_modelos = []\n",
    "\n",
    "for comb in combinacoes:\n",
    "    X = df_treino[list(comb)]\n",
    "    y = df_treino['Status_bin']\n",
    "    \n",
    "    if X.isnull().sum().any():\n",
    "        X = X.fillna(X.mean())\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    for nome_modelo, modelo in models.items():\n",
    "        accs, maes, rmses = [], [], []\n",
    "\n",
    "        for seed in range(50):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=seed)\n",
    "            modelo.fit(X_train, y_train)\n",
    "            y_pred = modelo.predict(X_test)\n",
    "\n",
    "            accs.append(accuracy_score(y_test, y_pred))\n",
    "            maes.append(mean_absolute_error(y_test, y_pred))\n",
    "            rmses.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "        resultados_modelos.append({\n",
    "            'Features': ', '.join(comb),\n",
    "            'Modelo': nome_modelo,\n",
    "            'Acur√°cia M√©dia': np.mean(accs),\n",
    "            'MAE M√©dio': np.mean(maes),\n",
    "            'RMSE M√©dio': np.mean(rmses)\n",
    "        })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados_modelos)\n",
    "top3 = df_resultados.sort_values(by='Acur√°cia M√©dia', ascending=False).head(3)\n",
    "\n",
    "print(\"üèÜ Top 3 Modelos por Acur√°cia M√©dia:\\n\")\n",
    "print(top3[['Modelo', 'Features', 'Acur√°cia M√©dia', 'MAE M√©dio', 'RMSE M√©dio']])\n",
    "\n",
    "logit_row = df_resultados[df_resultados['Modelo'] == 'Logit'].sort_values(by='Acur√°cia M√©dia', ascending=False).iloc[0]\n",
    "logit_comb = logit_row['Features'].split(', ')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tendo em vista que o modelo **Logit** apresentou a **melhor acur√°cia m√©dia (0.89)** entre os modelos avaliados, ele foi selecionado como o modelo principal para ser salvo e utilizado nas previs√µes.\n",
    "\n",
    "* √â importante destacar que, por se tratar de um modelo de classifica√ß√£o, o **Logit (Regress√£o Log√≠stica)** **n√£o utiliza o R¬≤ como m√©trica adequada** para avalia√ß√£o. O R¬≤ √© uma m√©trica de regress√£o, e sua aplica√ß√£o nesse contexto pode gerar interpreta√ß√µes incorretas. Portanto, o foco da avalia√ß√£o foi baseado principalmente na acur√°cia, no MAE e no RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo Logit e scaler salvos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "X_treino_final = df_treino[logit_comb]\n",
    "y_treino_final = df_treino['Status_bin']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_treino_scaled = scaler.fit_transform(X_treino_final)\n",
    "\n",
    "modelo_final = LogisticRegression(max_iter=1000)\n",
    "modelo_final.fit(X_treino_scaled, y_treino_final)\n",
    "\n",
    "os.makedirs('modelos', exist_ok=True)\n",
    "\n",
    "with open('modelos/modelo_logit_status.pkl', 'wb') as f:\n",
    "    pickle.dump(modelo_final, f)\n",
    "\n",
    "with open('modelos/scaler_logit_status.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"‚úÖ Modelo Logit e scaler salvos com sucesso!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previs√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìâ Previs√£o de Rebaixamento 2025:\n",
      "                Clube  Prob_Rebaixamento Rebaixado\n",
      "239          Mirassol               51.0       Sim\n",
      "238         Juventude               50.6       Sim\n",
      "237             Cear√°               31.4       Sim\n",
      "236      Sport Recife               23.8       Sim\n",
      "235           Vit√≥ria               13.6       N√£o\n",
      "234         Fortaleza               10.7       N√£o\n",
      "232        Fluminense                1.4       N√£o\n",
      "233        Bragantino                1.2       N√£o\n",
      "231         S√£o Paulo                0.7       N√£o\n",
      "230          Vasco da                0.4       N√£o\n",
      "228            Gr√™mio                0.2       N√£o\n",
      "225            Santos                0.2       N√£o\n",
      "229             Bahia                0.1       N√£o\n",
      "224     Internacional                0.1       N√£o\n",
      "226          Cruzeiro                0.1       N√£o\n",
      "227  Atl√©tico Mineiro                0.1       N√£o\n",
      "223       Corinthians                0.0       N√£o\n",
      "222          Botafogo                0.0       N√£o\n",
      "221          Flamengo                0.0       N√£o\n",
      "220         Palmeiras                0.0       N√£o\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o modelo e o scaler salvos\n",
    "with open('modelos/modelo_logit_status.pkl', 'rb') as f:\n",
    "    modelo_logit = pickle.load(f)\n",
    "\n",
    "with open('modelos/scaler_logit_status.pkl', 'rb') as f:\n",
    "    scaler_logit = pickle.load(f)\n",
    "\n",
    "# Carregar os dados\n",
    "file_path = r\"dados/BASE_FINAL.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name=\"CLUBES\")\n",
    "\n",
    "# Filtrar os dados para a temporada de 2025\n",
    "df_prev_2025 = df[df['Temporada'] == 2025].copy()\n",
    "\n",
    "# Garantir que todas as colunas necess√°rias est√£o presentes\n",
    "features_usadas = list(scaler_logit.feature_names_in_)\n",
    "missing_cols = set(features_usadas) - set(df_prev_2025.columns)\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Colunas faltando no DataFrame: {missing_cols}\")\n",
    "\n",
    "# Selecionar e escalonar os dados\n",
    "X_prev_2025 = df_prev_2025[features_usadas]\n",
    "X_prev_scaled = scaler_logit.transform(X_prev_2025)\n",
    "\n",
    "# Fazer a previs√£o de probabilidade de rebaixamento\n",
    "prob_rebaixamento = 1 - modelo_logit.predict_proba(X_prev_scaled)[:, 1]\n",
    "\n",
    "# Criar o DataFrame com o resultado\n",
    "df_resultado_2025 = df_prev_2025[['Clube']].copy()\n",
    "df_resultado_2025['Prob_Rebaixamento'] = prob_rebaixamento * 100\n",
    "df_resultado_2025['Prob_Rebaixamento'] = df_resultado_2025['Prob_Rebaixamento'].round(1)\n",
    "df_resultado_2025['Rebaixado'] = 'N√£o'\n",
    "df_resultado_2025.loc[df_resultado_2025['Prob_Rebaixamento'].nlargest(4).index, 'Rebaixado'] = 'Sim'\n",
    "\n",
    "# Resultado\n",
    "print(\"\\nüìâ Previs√£o de Rebaixamento 2025:\")\n",
    "print(df_resultado_2025.sort_values(by='Prob_Rebaixamento', ascending=False))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucia\\AppData\\Local\\Temp\\ipykernel_19032\\2698453965.py:7: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  df_resultado_2025_sorted.style.format({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3d3e7_row0_col2, #T_3d3e7_row1_col2, #T_3d3e7_row2_col2, #T_3d3e7_row3_col2 {\n",
       "  color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3d3e7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3d3e7_level0_col0\" class=\"col_heading level0 col0\" >Clube</th>\n",
       "      <th id=\"T_3d3e7_level0_col1\" class=\"col_heading level0 col1\" >Prob_Rebaixamento</th>\n",
       "      <th id=\"T_3d3e7_level0_col2\" class=\"col_heading level0 col2\" >Rebaixado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3d3e7_row0_col0\" class=\"data row0 col0\" >Mirassol</td>\n",
       "      <td id=\"T_3d3e7_row0_col1\" class=\"data row0 col1\" >51.00%</td>\n",
       "      <td id=\"T_3d3e7_row0_col2\" class=\"data row0 col2\" >Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3d3e7_row1_col0\" class=\"data row1 col0\" >Juventude</td>\n",
       "      <td id=\"T_3d3e7_row1_col1\" class=\"data row1 col1\" >50.60%</td>\n",
       "      <td id=\"T_3d3e7_row1_col2\" class=\"data row1 col2\" >Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3d3e7_row2_col0\" class=\"data row2 col0\" >Cear√°</td>\n",
       "      <td id=\"T_3d3e7_row2_col1\" class=\"data row2 col1\" >31.40%</td>\n",
       "      <td id=\"T_3d3e7_row2_col2\" class=\"data row2 col2\" >Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3d3e7_row3_col0\" class=\"data row3 col0\" >Sport Recife</td>\n",
       "      <td id=\"T_3d3e7_row3_col1\" class=\"data row3 col1\" >23.80%</td>\n",
       "      <td id=\"T_3d3e7_row3_col2\" class=\"data row3 col2\" >Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3d3e7_row4_col0\" class=\"data row4 col0\" >Vit√≥ria</td>\n",
       "      <td id=\"T_3d3e7_row4_col1\" class=\"data row4 col1\" >13.60%</td>\n",
       "      <td id=\"T_3d3e7_row4_col2\" class=\"data row4 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3d3e7_row5_col0\" class=\"data row5 col0\" >Fortaleza</td>\n",
       "      <td id=\"T_3d3e7_row5_col1\" class=\"data row5 col1\" >10.70%</td>\n",
       "      <td id=\"T_3d3e7_row5_col2\" class=\"data row5 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3d3e7_row6_col0\" class=\"data row6 col0\" >Fluminense</td>\n",
       "      <td id=\"T_3d3e7_row6_col1\" class=\"data row6 col1\" >1.40%</td>\n",
       "      <td id=\"T_3d3e7_row6_col2\" class=\"data row6 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3d3e7_row7_col0\" class=\"data row7 col0\" >Bragantino</td>\n",
       "      <td id=\"T_3d3e7_row7_col1\" class=\"data row7 col1\" >1.20%</td>\n",
       "      <td id=\"T_3d3e7_row7_col2\" class=\"data row7 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3d3e7_row8_col0\" class=\"data row8 col0\" >S√£o Paulo</td>\n",
       "      <td id=\"T_3d3e7_row8_col1\" class=\"data row8 col1\" >0.70%</td>\n",
       "      <td id=\"T_3d3e7_row8_col2\" class=\"data row8 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3d3e7_row9_col0\" class=\"data row9 col0\" >Vasco da</td>\n",
       "      <td id=\"T_3d3e7_row9_col1\" class=\"data row9 col1\" >0.40%</td>\n",
       "      <td id=\"T_3d3e7_row9_col2\" class=\"data row9 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_3d3e7_row10_col0\" class=\"data row10 col0\" >Gr√™mio</td>\n",
       "      <td id=\"T_3d3e7_row10_col1\" class=\"data row10 col1\" >0.20%</td>\n",
       "      <td id=\"T_3d3e7_row10_col2\" class=\"data row10 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_3d3e7_row11_col0\" class=\"data row11 col0\" >Santos</td>\n",
       "      <td id=\"T_3d3e7_row11_col1\" class=\"data row11 col1\" >0.20%</td>\n",
       "      <td id=\"T_3d3e7_row11_col2\" class=\"data row11 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_3d3e7_row12_col0\" class=\"data row12 col0\" >Bahia</td>\n",
       "      <td id=\"T_3d3e7_row12_col1\" class=\"data row12 col1\" >0.10%</td>\n",
       "      <td id=\"T_3d3e7_row12_col2\" class=\"data row12 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_3d3e7_row13_col0\" class=\"data row13 col0\" >Internacional</td>\n",
       "      <td id=\"T_3d3e7_row13_col1\" class=\"data row13 col1\" >0.10%</td>\n",
       "      <td id=\"T_3d3e7_row13_col2\" class=\"data row13 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_3d3e7_row14_col0\" class=\"data row14 col0\" >Cruzeiro</td>\n",
       "      <td id=\"T_3d3e7_row14_col1\" class=\"data row14 col1\" >0.10%</td>\n",
       "      <td id=\"T_3d3e7_row14_col2\" class=\"data row14 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_3d3e7_row15_col0\" class=\"data row15 col0\" >Atl√©tico Mineiro</td>\n",
       "      <td id=\"T_3d3e7_row15_col1\" class=\"data row15 col1\" >0.10%</td>\n",
       "      <td id=\"T_3d3e7_row15_col2\" class=\"data row15 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_3d3e7_row16_col0\" class=\"data row16 col0\" >Corinthians</td>\n",
       "      <td id=\"T_3d3e7_row16_col1\" class=\"data row16 col1\" >0.00%</td>\n",
       "      <td id=\"T_3d3e7_row16_col2\" class=\"data row16 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_3d3e7_row17_col0\" class=\"data row17 col0\" >Botafogo</td>\n",
       "      <td id=\"T_3d3e7_row17_col1\" class=\"data row17 col1\" >0.00%</td>\n",
       "      <td id=\"T_3d3e7_row17_col2\" class=\"data row17 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_3d3e7_row18_col0\" class=\"data row18 col0\" >Flamengo</td>\n",
       "      <td id=\"T_3d3e7_row18_col1\" class=\"data row18 col1\" >0.00%</td>\n",
       "      <td id=\"T_3d3e7_row18_col2\" class=\"data row18 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3d3e7_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_3d3e7_row19_col0\" class=\"data row19 col0\" >Palmeiras</td>\n",
       "      <td id=\"T_3d3e7_row19_col1\" class=\"data row19 col1\" >0.00%</td>\n",
       "      <td id=\"T_3d3e7_row19_col2\" class=\"data row19 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x162d96c1780>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_resultado_2025_sorted = df_resultado_2025.sort_values(by='Prob_Rebaixamento', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_resultado_2025_sorted['Prob_Rebaixamento'] = df_resultado_2025_sorted['Prob_Rebaixamento'] / 100\n",
    "\n",
    "df_resultado_2025_sorted.style.format({\n",
    "    'Prob_Rebaixamento': '{:.2%}'\n",
    "}).applymap(lambda x: 'color: red' if isinstance(x, str) and 'Sim' in x else '', subset=['Rebaixado'])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "novo_ambiente_python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
